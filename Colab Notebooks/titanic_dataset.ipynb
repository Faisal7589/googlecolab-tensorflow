{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPgGkK/uOXRrsUV7eoyOqM7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q sklearn"],"metadata":{"id":"hsWUCJQ0MEk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorflow_version 2.x"],"metadata":{"id":"nKSnj3WeSxNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","from six.moves import urllib\n","\n","import tensorflow.compat.v2.feature_column as fc\n","\n","import tensorflow as tf\n"],"metadata":{"id":"JhvAvuxr9fJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training data\n","dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing data\n","y_train = dftrain.pop('survived')\n","y_eval = dfeval.pop('survived')\n","\n","CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n","                       'embark_town', 'alone']\n","NUMERIC_COLUMNS = ['age', 'fare']\n","\n","feature_columns = []\n","for feature_name in CATEGORICAL_COLUMNS:\n","  vocabulary = dftrain[feature_name].unique()  # gets a list of all unique values from given feature column\n","  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n","\n","for feature_name in NUMERIC_COLUMNS:\n","  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n","\n","print(feature_columns)"],"metadata":{"id":"7gPCdcCqSpkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n","  def input_function():  # inner function, this will be returned\n","    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n","    if shuffle:\n","      ds = ds.shuffle(1000)  # randomize order of data\n","    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n","    print(ds)\n","    return ds  # return a batch of the dataset\n","  return input_function  # return a function object for use\n","\n","train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n","eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n","\n","linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n","\n","linear_est.train(train_input_fn)  # train\n","result = linear_est.evaluate(train_input_fn)  # get model metrics/stats by testing on tetsing data\n","\n","clear_output()  # clears consoke output\n","print(result['accuracy'])  # the result variable is simply a dict of stats about our model\n"],"metadata":{"id":"m8Hy8kf2hD4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_dicts = list(linear_est.predict(eval_input_fn))\n","probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n","\n","probs.plot(kind='hist', bins=20, title='predicted probabilities')\n"],"metadata":{"id":"69dcVi9QispY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"hSGIeiuCkEr1"}}]}