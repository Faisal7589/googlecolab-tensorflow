{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2901,"status":"ok","timestamp":1654775740552,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"rZresCRJtfx-","outputId":"97ad15b9-831e-4541-b420-cf644e985c9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `2.x  # this line is not required unless you are in a notebook`. This will be interpreted as: `2.x`.\n","\n","\n","TensorFlow 2.x selected.\n"]}],"source":["%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n","from keras.preprocessing import sequence\n","import keras\n","import tensorflow as tf\n","import os\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654775740553,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"XZhUc5-0uAK-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"84867115-51e3-4950-cb60-9314b8255aa9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n","1130496/1115394 [==============================] - 0s 0us/step\n"]}],"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1654775740553,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"q564L4B_uD47","outputId":"6620478f-1927-4cd2-c7c2-d752c62d74cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of text: 1115394 characters\n"]}],"source":["# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print ('Length of text: {} characters'.format(len(text)))"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654775740553,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"20WLXh60uFj_"},"outputs":[],"source":["vocab = sorted(set(text))\n","# Creating a mapping from unique characters to indices\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","def text_to_int(text):\n","  return np.array([char2idx[c] for c in text])\n","\n","text_as_int = text_to_int(text)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4436,"status":"ok","timestamp":1654775744983,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"1hyptTC5uHFv","outputId":"d090f7b1-8904-4407-d919-7251dbb95845"},"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen\n"]}],"source":["def int_to_text(ints):\n","  try:\n","    ints = ints.numpy()\n","  except:\n","    pass\n","  return ''.join(idx2char[ints])\n","\n","print(int_to_text(text_as_int[:13]))"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654775744983,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"JBkyrS1wuIrW"},"outputs":[],"source":["seq_length = 100  # length of sequence for a training example\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","# Create training examples / targets\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654775744983,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"yT6JEddhuJ3a"},"outputs":[],"source":["sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654775744984,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"3_4rV2SUuKmC"},"outputs":[],"source":["def split_input_target(chunk):  # for the example: hello\n","    input_text = chunk[:-1]  # hell\n","    target_text = chunk[1:]  # ello\n","    return input_text, target_text  # hell, ello\n","\n","dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654775744984,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"Oh2wovxUuLel","outputId":"455b6974-37b9-436c-aa1d-85b8e41f1701"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","EXAMPLE\n","\n","INPUT\n","First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You\n","\n","OUTPUT\n","irst Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You \n","\n","\n","EXAMPLE\n","\n","INPUT\n","are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you \n","\n","OUTPUT\n","re all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you k\n"]}],"source":["for x, y in dataset.take(2):\n","  print(\"\\n\\nEXAMPLE\\n\")\n","  print(\"INPUT\")\n","  print(int_to_text(x))\n","  print(\"\\nOUTPUT\")\n","  print(int_to_text(y))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654775744984,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"iWW8-bSKuMlS"},"outputs":[],"source":["BATCH_SIZE = 64\n","VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n","EMBEDDING_DIM = 256\n","RNN_UNITS = 1024\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1379,"status":"ok","timestamp":1654775746354,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"Oe8wjKcnuN5k","outputId":"dd06f454-2878-4342-c778-d8fabf6445d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (64, None, 256)           16640     \n","                                                                 \n"," lstm (LSTM)                 (64, None, 1024)          5246976   \n","                                                                 \n"," dense (Dense)               (64, None, 65)            66625     \n","                                                                 \n","=================================================================\n","Total params: 5,330,241\n","Trainable params: 5,330,241\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model\n","\n","model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n","model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10126,"status":"ok","timestamp":1654775756477,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"ftZG9sypuQAt","outputId":"12161ea1-7b6b-4382-b24a-e2f02c147a95"},"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in data.take(1):\n","  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n","  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654775756478,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"ikdoc1wVuVRb"},"outputs":[],"source":["def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654775756478,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"rWW7Kk1guW50"},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654775756479,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"3TX8cA0IuXqu"},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":838235,"status":"ok","timestamp":1654776594705,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"UEHFaHT-uZgR","outputId":"5b853595-5670-4cea-817d-a76e325ed554"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","172/172 [==============================] - 15s 66ms/step - loss: 2.5437\n","Epoch 2/50\n","172/172 [==============================] - 13s 66ms/step - loss: 1.8565\n","Epoch 3/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.6145\n","Epoch 4/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.4871\n","Epoch 5/50\n","172/172 [==============================] - 13s 69ms/step - loss: 1.4100\n","Epoch 6/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.3551\n","Epoch 7/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.3109\n","Epoch 8/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.2725\n","Epoch 9/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.2354\n","Epoch 10/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.2003\n","Epoch 11/50\n","172/172 [==============================] - 13s 68ms/step - loss: 1.1627\n","Epoch 12/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.1263\n","Epoch 13/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.0880\n","Epoch 14/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.0477\n","Epoch 15/50\n","172/172 [==============================] - 13s 67ms/step - loss: 1.0067\n","Epoch 16/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.9662\n","Epoch 17/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.9236\n","Epoch 18/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.8827\n","Epoch 19/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.8434\n","Epoch 20/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.8061\n","Epoch 21/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7714\n","Epoch 22/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7373\n","Epoch 23/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.7076\n","Epoch 24/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6795\n","Epoch 25/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.6549\n","Epoch 26/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.6324\n","Epoch 27/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.6084\n","Epoch 28/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5925\n","Epoch 29/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.5744\n","Epoch 30/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5603\n","Epoch 31/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.5466\n","Epoch 32/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5333\n","Epoch 33/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.5214\n","Epoch 34/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.5115\n","Epoch 35/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.5025\n","Epoch 36/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4925\n","Epoch 37/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4862\n","Epoch 38/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4792\n","Epoch 39/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4727\n","Epoch 40/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4668\n","Epoch 41/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4609\n","Epoch 42/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4560\n","Epoch 43/50\n","172/172 [==============================] - 13s 69ms/step - loss: 0.4510\n","Epoch 44/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4475\n","Epoch 45/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4432\n","Epoch 46/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4413\n","Epoch 47/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4387\n","Epoch 48/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4359\n","Epoch 49/50\n","172/172 [==============================] - 13s 68ms/step - loss: 0.4317\n","Epoch 50/50\n","172/172 [==============================] - 13s 67ms/step - loss: 0.4314\n"]}],"source":["history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1654776594706,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"1E8ykKgbubFs"},"outputs":[],"source":["model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":760,"status":"ok","timestamp":1654776595458,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"RFMqWyxSucYu"},"outputs":[],"source":["model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1, None]))"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1654776689060,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"lOx7HZMxudMm"},"outputs":[],"source":["checkpoint_num = 10\n","model.build(tf.TensorShape([1, None]))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":390,"status":"ok","timestamp":1654776692341,"user":{"displayName":"Faisal Hassan","userId":"08364909878214706410"},"user_tz":-240},"id":"i3O0xfdzueCO"},"outputs":[],"source":["def generate_text(model, start_string):\n","  # Evaluation step (generating text using the learned model)\n","\n","  # Number of characters to generate\n","  num_generate = 800\n","\n","  # Converting our start string to numbers (vectorizing)\n","  input_eval = [char2idx[s] for s in start_string]\n","  input_eval = tf.expand_dims(input_eval, 0)\n","\n","  # Empty string to store our results\n","  text_generated = []\n","\n","  # Low temperatures results in more predictable text.\n","  # Higher temperatures results in more surprising text.\n","  # Experiment to find the best setting.\n","  temperature = 1.0\n","\n","  # Here batch size == 1\n","  model.reset_states()\n","  for i in range(num_generate):\n","      predictions = model(input_eval)\n","      # remove the batch dimension\n","    \n","      predictions = tf.squeeze(predictions, 0)\n","\n","      # using a categorical distribution to predict the character returned by the model\n","      predictions = predictions / temperature\n","      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","\n","      # We pass the predicted character as the next input to the model\n","      # along with the previous hidden state\n","      input_eval = tf.expand_dims([predicted_id], 0)\n","\n","      text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"]}],"metadata":{"accelerator":"GPU","colab":{"name":"Untitled6.ipynb","provenance":[],"authorship_tag":"ABX9TyO5YdgUNfauSRx7+OWfA/fw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}